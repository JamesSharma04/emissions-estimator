{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          instance  scope3hourly    0%   10%    50  100%\n",
      "0        a1.medium           1.8   1.2   1.9   3.2   4.2\n",
      "1         a1.large           3.7   2.4   3.8   6.4   8.5\n",
      "2        a1.xlarge           7.4   4.8   7.6  12.7  17.0\n",
      "3       a1.2xlarge          14.8   9.5  15.2  25.4  34.0\n",
      "4       a1.4xlarge          29.6  19.0  30.3  50.9  67.9\n",
      "..             ...           ...   ...   ...   ...   ...\n",
      "616    db.t2.small           0.9   2.0   3.3   5.3   7.0\n",
      "617   db.t2.medium           1.8   4.0   6.6  10.7  14.1\n",
      "618    db.t2.large           1.8   4.8   7.8  12.3  16.5\n",
      "619   db.t2.xlarge           3.6   9.6  15.7  24.6  33.0\n",
      "620  db.t2.2xlarge           7.1  19.2  31.4  49.1  66.0\n",
      "\n",
      "[621 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# use original ec2 file\n",
    "path = \"../raw/AWS EC2 Carbon Footprint Dataset - EC2 Instances Dataset.csv\"\n",
    "df = pd.read_csv(path, decimal=',')\n",
    "\n",
    "# create and save new csv with relevant data \n",
    "d = {'instance': df[\"Instance type\"], 'scope3hourly': df[\"Instance Hourly Manufacturing Emissions (gCOâ‚‚eq)\"], '0%': df[\"Instance @ Idle\"],\n",
    "     '10%': df[\"Instance @ 10%\"], '50': df[\"Instance @ 50%\"], '100%': df[\"Instance @ 100%\"]}\n",
    "slimdf = pd.DataFrame(data=d)\n",
    "print(slimdf)\n",
    "dfpath = Path(f\"../processed/teads/ec2_instances.csv\")\n",
    "slimdf.to_csv(dfpath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2\n",
      "proportion of values with P <0.02:  1.0\n",
      "proportion of values with R >0.95:  1.0\n",
      "proportion of curves with error <2:  0.9790660225442834\n",
      "proportion of curves with error <1:  0.9597423510466989\n",
      "proportion of curves with error <0.1:  0.5104669887278583\n"
     ]
    }
   ],
   "source": [
    "'''save a power curve to a file for each instance type including error metrics'''\n",
    "\n",
    "x = [0, 10, 50, 100]\n",
    "y=slimdf.values[0][1:]\n",
    "print(y[-1])\n",
    "#max_rating=slimdf.values[-1]\n",
    "#print(y)\n",
    "#slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "# check that data is present and can be indexed\n",
    "dfs=[]\n",
    "for index, row in slimdf.iterrows():\n",
    "    y = [list(row[2:].values)]\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "\n",
    "    dfs.append(pd.DataFrame(data={'instance_type':[row[0]], 'scope3_hourly':[row[1]],'slope':[slope],'intercept':[intercept],'error':[std_err],'r_value':[r_value],'p_value':[p_value],'max_power':[row[-1]]},index=[row[0]]))\n",
    "all=pd.concat(dfs)\n",
    "\n",
    "# result implies that the power curves are not flat i.e. there is something to be gained from a granular utilisation\n",
    "print(\"proportion of values with P <0.02: \",len(all[all['p_value']<0.05])/len(all))\n",
    "\n",
    "# the power curves are fit well by linregress, and that non-linear methods is likely unecessary\n",
    "print(\"proportion of values with R >0.95: \",len(all[all['r_value']>0.95])/len(all))\n",
    "\n",
    "# most power curves have a low average deviation from the plotted data\n",
    "# however there are a few with pretty high error and these should be investigated \n",
    "print(\"proportion of curves with error <2: \",len(all[all['error']<2])/len(all))\n",
    "print(\"proportion of curves with error <1: \",len(all[all['error']<1])/len(all))\n",
    "print(\"proportion of curves with error <0.1: \",len(all[all['error']<0.1])/len(all))\n",
    "dfpath = Path(f\"../processed/teads/instancelines.csv\")\n",
    "all.to_csv(dfpath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[19.2 31.4 49.1 66. ]]\n"
     ]
    }
   ],
   "source": [
    "f = interp1d(x, y)\n",
    "\n",
    "f2 = interp1d(x, y, kind='cubic')\n",
    "print(f(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
