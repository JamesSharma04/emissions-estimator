{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.datasets import make_classification \n",
    "import numpy as np \n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create dataset of power usage estimates for each entry in trace dataset '''\n",
    "\n",
    "power_curves = pd.read_csv(\"../processed/teads/instancelines.csv\")\n",
    "all_runs = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "#print(power_curves.loc[[\"c4.2xlarge\"]:])\n",
    "#print(power_curves[\"cluster_type\"])\n",
    "power_curves = power_curves.set_index(\"cluster_type\")\n",
    "dfs=[]\n",
    "\n",
    "for index, row in all_runs.iterrows():\n",
    "    avgutil=row['avgcpu']\n",
    "    instance=row['cluster_type']\n",
    "    #print(row['cluster_type'],row['avgcpu'])\n",
    "    hourpower=power_curves.loc[instance,'slope']* avgutil + power_curves.loc[instance,'intercept']\n",
    "    powerused=(hourpower/3600)*row['elapsed_time']\n",
    "    df = pd.DataFrame(data={'cluster_type' : row['name'],'power':powerused}, index=['cluster_type'])\n",
    "    dfs.append(df)\n",
    "all=pd.concat(dfs)\n",
    "dfpath = Path(f\"../processed/power.csv\")\n",
    "all.to_csv(dfpath, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUE = 1.135\n",
    "CARBON_INTENSITY = 228\n",
    "power_estimates = pd.read_csv(\"../processed/power.csv\")\n",
    "dfs=[]\n",
    "dfpath = Path(f\"../processed/carbon.csv\")\n",
    "all.to_csv(dfpath, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'hi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mfloat\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mhi\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'hi'"
     ]
    }
   ],
   "source": [
    "print(float(\"hi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''New attempt at gradient boosting using all features'''\n",
    "\n",
    "def train_gbr(df,target):\n",
    "\n",
    "\n",
    "    # label\n",
    "    y = df.pop(target)\n",
    "\n",
    "    # drop runtime/util if not already - not sure if this is correct?\n",
    "    #df.drop(columns=['avgcpu','elapsed_time'], inplace=True, errors='ignore')\n",
    "    # feature vector\n",
    "    name = df.pop(\"name\")\n",
    "    X = df\n",
    "    unencoded_X=X.copy()\n",
    "    # get columns containing text, apply label encoder and transform text to numbers\n",
    "    cat_cols = X.select_dtypes(include='object').columns\n",
    "    d = defaultdict(preprocessing.LabelEncoder)\n",
    "    X[cat_cols] = X[cat_cols].apply(lambda x: d[x.name].fit_transform(x.astype(str)))\n",
    "\n",
    "    # split dataset\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=0)\n",
    "\n",
    "    # set regression model parameters to tweak later and see how results change\n",
    "    param_grid = {\n",
    "        \"n_estimators\":[500,1000],\n",
    "        \"max_depth\": [4,8],\n",
    "        \"min_samples_split\": [2,4],\n",
    "        \"learning_rate\": [0.005, 0.01, 0.05],\n",
    "        \"loss\": [\"squared_error\"]\n",
    "    }\n",
    "\n",
    "    clf =  GradientBoostingRegressor()\n",
    "    reg = GridSearchCV(clf, param_grid, cv=2)\n",
    "    print(param_grid)\n",
    "    reg.fit(X_train, y_train)\n",
    "    optimised_gbr = reg.best_estimator_\n",
    "    print(reg.best_params_)\n",
    "    # attempt to make df of resultant data\n",
    "    y_pred = reg.predict(X)\n",
    "    results_features=pd.DataFrame(data={\"true\":y,\"predicted\":y_pred,\"name\":name})\n",
    "    for col in unencoded_X.columns:\n",
    "        if col in cat_cols:\n",
    "            results_features[col] = (d[col].inverse_transform(X[col]))\n",
    "        else:\n",
    "            results_features[col]=X[col]\n",
    "    dfpath = Path(f\"../processed/gradboosttest_time_full.csv\")\n",
    "    results_features.to_csv(dfpath, index=False)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "    print(f'MSE = {round(mse,2)}')\n",
    "\n",
    "    # generate plots \n",
    "    test_score = np.zeros((reg.best_params_[\"n_estimators\"],), dtype=np.float64)\n",
    "    print(reg.cv_results_)\n",
    "    for i, y_pred in enumerate(optimised_gbr.cv_results_(X_test)):\n",
    "        test_score[i] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.title(\"Deviance\")\n",
    "    plt.plot(\n",
    "        np.arange(reg.best_params_[\"n_estimators\"]) + 1,\n",
    "        reg.train_score_,\n",
    "        \"b-\",\n",
    "        label=\"Training Set Deviance\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        np.arange(reg.best_params_[\"n_estimators\"]) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    "    )\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.xlabel(\"Boosting Iterations\")\n",
    "    plt.ylabel(\"Deviance\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    feature_importance = reg.feature_importances_\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "    fig = plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "    plt.yticks(pos, np.array(df.columns)[sorted_idx])\n",
    "    plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "    result = permutation_importance(\n",
    "        reg, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    "    )\n",
    "    sorted_idx = result.importances_mean.argsort()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(\n",
    "        result.importances[sorted_idx].T,\n",
    "        vert=False,\n",
    "        labels=np.array(df.columns)[sorted_idx],\n",
    "    )\n",
    "    plt.title(\"Permutation Importance (test set)\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(reg\u001b[39m.\u001b[39mcv_results_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reg' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "train_gbr(df,target='avgcpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [500, 1000], 'max_depth': [4, 8], 'min_samples_split': [2, 4], 'learning_rate': [0.005, 0.01, 0.05], 'loss': ['squared_error']}\n",
      "{'learning_rate': 0.05, 'loss': 'squared_error', 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 1000}\n",
      "MSE = 477752.63\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "train_gbr(df, target='elapsed_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4]\n",
      " [ 6]\n",
      " [ 8]\n",
      " [10]\n",
      " [12]\n",
      " [16]\n",
      " [20]\n",
      " [24]\n",
      " [32]\n",
      " [40]\n",
      " [48]]\n",
      "           noof_nodes        job  predicted_util\n",
      "join                4       join       71.204313\n",
      "join                6       join       64.699194\n",
      "join                8       join       58.049283\n",
      "join               10       join       54.826318\n",
      "join               12       join       48.734093\n",
      "...               ...        ...             ...\n",
      "wordcount          20  wordcount       49.314553\n",
      "wordcount          24  wordcount       49.023703\n",
      "wordcount          32  wordcount       45.724993\n",
      "wordcount          40  wordcount       43.323302\n",
      "wordcount          48  wordcount       45.209484\n",
      "\n",
      "[88 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "'''old script to calculate node count interpolation using gbr'''\n",
    "\n",
    "from scipy import stats \n",
    "import numpy as np \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "''' interpolate using node count with gradient boosting regression'''\n",
    "def node_interpolation(df,nodecounts,jobs):\n",
    "    dfs = []\n",
    "    x=sorted(nodecounts)\n",
    "    oneDx = np.array(x)\n",
    "    x=oneDx.reshape(-1, 1)\n",
    "    print(x)\n",
    "    for j in jobs:\n",
    "        filter_ = df['workload']==j\n",
    "        y = (df[filter_].groupby(['node_count'])['avgcpu'].mean(numeric_only=True))\n",
    "        #slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        #dfs.append(pd.DataFrame(data={'workload':[j],'slope':[slope],'intercept':[intercept],'error':[std_err],'r_value':[r_value],'p_value':[p_value],},index=[j]))\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(x, y)\n",
    "        y_pred=gbr.predict(x)\n",
    "        jarray=[j for i in range(len(y_pred))]\n",
    "        dfs.append(pd.DataFrame(data={'noof_nodes':oneDx, 'job':j, 'predicted_util':y_pred},index=jarray))\n",
    "\n",
    "        # attempting to use cross validation \n",
    "        '''\n",
    "        loo = LeaveOneOut()\n",
    "        loo.get_n_splits(x)\n",
    "        # Use LOOCV to evaluate the model\n",
    "        scores = []\n",
    "        for train_index, test_index in loo.split(x):\n",
    "            X_train, X_test = x[train_index], x[test_index]\n",
    "            y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "            gbr.fit(X_train, y_train)\n",
    "            scores.append(gbr.score(X_test, y_test))\n",
    "\n",
    "        '''\n",
    "    #print(scores)\n",
    "    all=pd.concat(dfs)\n",
    "    return all\n",
    "\n",
    "df = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "nodecounts=df[\"node_count\"].unique()\n",
    "jobs=df[\"workload\"].unique()\n",
    "\n",
    "results = node_interpolation(df,nodecounts,jobs)\n",
    "dfpath = Path(f\"../processed/gradboosttest.csv\")\n",
    "results.to_csv(dfpath, index=False)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=99.0.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [91], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m nodecounts\u001b[39m=\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mnode_count\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[0;32m     20\u001b[0m jobs\u001b[39m=\u001b[39mdf[\u001b[39m\"\u001b[39m\u001b[39mworkload\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m---> 21\u001b[0m results \u001b[39m=\u001b[39m node_interpolation(df,nodecounts,jobs)\n\u001b[0;32m     23\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "Cell \u001b[1;32mIn [91], line 13\u001b[0m, in \u001b[0;36mnode_interpolation\u001b[1;34m(df, nodecounts, jobs)\u001b[0m\n\u001b[0;32m     11\u001b[0m     gbr \u001b[39m=\u001b[39m GradientBoostingRegressor()\n\u001b[0;32m     12\u001b[0m     gbr\u001b[39m.\u001b[39mfit(x, y)\n\u001b[1;32m---> 13\u001b[0m     \u001b[39mprint\u001b[39m(gbr\u001b[39m.\u001b[39;49mpredict(\u001b[39m99\u001b[39;49m))\n\u001b[0;32m     14\u001b[0m     dfs[j]\u001b[39m=\u001b[39mgbr\n\u001b[0;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m dfs\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive - University of Glasgow\\_Fourth Year\\Project\\emissions-estimator\\env\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1963\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1948\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m   1949\u001b[0m     \u001b[39m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \n\u001b[0;32m   1951\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1961\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1962\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1964\u001b[0m         X, dtype\u001b[39m=\u001b[39;49mDTYPE, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1965\u001b[0m     )\n\u001b[0;32m   1966\u001b[0m     \u001b[39m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   1967\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raw_predict(X)\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive - University of Glasgow\\_Fourth Year\\Project\\emissions-estimator\\env\\lib\\site-packages\\sklearn\\base.py:577\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    576\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 577\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    578\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    579\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\Users\\crazy\\OneDrive - University of Glasgow\\_Fourth Year\\Project\\emissions-estimator\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:871\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    869\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 871\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    872\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    873\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    874\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    875\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    876\u001b[0m         )\n\u001b[0;32m    877\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    878\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=99.0.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "def node_interpolation(df,nodecounts,jobs):\n",
    "    dfs = pd.DataFrame()\n",
    "    x=sorted(nodecounts)\n",
    "    oneDx = np.array(x)\n",
    "    x=oneDx.reshape(-1, 1)\n",
    "    for j in jobs:\n",
    "        filter_ = df['workload']==j\n",
    "        y = (df[filter_].groupby(['node_count'])['avgcpu'].mean(numeric_only=True))\n",
    "        #slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "        #dfs.append(pd.DataFrame(data={'workload':[j],'slope':[slope],'intercept':[intercept],'error':[std_err],'r_value':[r_value],'p_value':[p_value],},index=[j]))\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        gbr.fit(x, y)\n",
    "        print(gbr.predict(99))\n",
    "        dfs[j]=gbr\n",
    "    return dfs\n",
    "\n",
    "    \n",
    "df = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "nodecounts=df[\"node_count\"].unique()\n",
    "jobs=df[\"workload\"].unique()\n",
    "results = node_interpolation(df,nodecounts,jobs)\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   node_count  cluster_type  workload  engine_type  data_size  elapsed_time\n",
      "0          10             0         0            1          0       305.064\n",
      "[49.12466288]\n",
      "[27.73574868]\n",
      "MSE = 35.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\crazy\\OneDrive - University of Glasgow\\_Fourth Year\\Project\\emissions-estimator\\env\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Playing around with .predict\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from collections import defaultdict\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df = pd.read_csv(\"../processed/scout/average_utils/averages.csv\")\n",
    "target='avgcpu'\n",
    "\n",
    "# label\n",
    "y = df.pop(target)\n",
    "\n",
    "# drop runtime/util if not already - not sure if this is correct?\n",
    "#df.drop(columns=['avgcpu','elapsed_time'], inplace=True, errors='ignore')\n",
    "# feature vector\n",
    "name = df.pop(\"name\")\n",
    "X = df\n",
    "unencoded_X=X.copy()\n",
    "# get columns containing text, apply label encoder and transform text to numbers\n",
    "cat_cols = X.select_dtypes(include='object').columns\n",
    "d = defaultdict(preprocessing.LabelEncoder)\n",
    "X[cat_cols] = X[cat_cols].apply(lambda x: d[x.name].fit_transform(x.astype(str)))\n",
    "\n",
    "# split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=0)\n",
    "\n",
    "# set regression model parameters to tweak later and see how results change\n",
    "params = {\n",
    "    \"n_estimators\":500,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"loss\": \"squared_error\",\n",
    "}\n",
    "\n",
    "reg = GradientBoostingRegressor(**params)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# attempt to make df of resultant data\n",
    "y_pred = reg.predict(X)\n",
    "print(X.head(1))\n",
    "print(reg.predict(X.head(1)))\n",
    "print(reg.predict(np.array([48,0,0,1,0,305]).reshape(1, -1)))\n",
    "results_features=pd.DataFrame(data={\"true\":y,\"predicted\":y_pred,\"name\":name})\n",
    "for col in unencoded_X.columns:\n",
    "    if col in cat_cols:\n",
    "        results_features[col] = (d[col].inverse_transform(X[col]))\n",
    "    else:\n",
    "        results_features[col]=X[col]\n",
    "dfpath = Path(f\"../processed/gradboosttest_time_full.csv\")\n",
    "results_features.to_csv(dfpath, index=False)\n",
    "\n",
    "mse = mean_squared_error(y_test, reg.predict(X_test))\n",
    "print(f'MSE = {round(mse,2)}')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d5d09f790366ce3cfc190a1b32374d118a80d9ac22d13bbd67747868894a94f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
